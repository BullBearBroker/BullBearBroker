# BullBearBroker

![Tests](https://github.com/bullbearbroker/bullbearbroker/actions/workflows/tests.yml/badge.svg)

BullBearBroker es una plataforma de an√°lisis financiero asistido por IA. Combina datos de
mercados tradicionales y cripto con m√≥dulos de noticias, alertas y un chatbot
especializado para acompa√±ar decisiones de trading en tiempo real.

## Visi√≥n del proyecto

- **Asistente integral** para traders minoristas que quieran monitorear acciones,
  criptomonedas y pares de divisas desde un √∫nico panel.
- **Alertas inteligentes** con disparadores personalizables y notificaciones en
  tiempo real (web, Telegram y Discord).
- **Contexto enriquecido** mediante noticias, an√°lisis de sentimiento y modelos
  de lenguaje que ayuden a interpretar la informaci√≥n del mercado.
- **Roadmap abierto** orientado a extender la plataforma con m√≥dulos de IA
  avanzados, nuevas fuentes de datos y experiencias conversacionales.

## Estructura de carpetas

```text
.
‚îú‚îÄ‚îÄ backend/                # API FastAPI, servicios y modelos SQLAlchemy
‚îú‚îÄ‚îÄ frontend/               # Frontend Next.js + Tailwind + SWR
‚îú‚îÄ‚îÄ docker-compose.yml      # Orquestaci√≥n de stack completo (backend, frontend, DB, Redis)
‚îú‚îÄ‚îÄ Dockerfile              # Imagen del backend (FastAPI + Uvicorn)
‚îú‚îÄ‚îÄ Makefile                # Atajos para Docker Compose y pruebas
‚îú‚îÄ‚îÄ .env.example            # Gu√≠a r√°pida hacia los ejemplos versionados
‚îî‚îÄ‚îÄ backend/tests/          # Suite de pruebas (autenticaci√≥n, alertas, servicios...)
```

## Gesti√≥n de variables de entorno

El repositorio incluye plantillas sin secretos para cada servicio:

- `./.env.example`: √≠ndice r√°pido que explica d√≥nde viven las variables reales.
- `backend/.env.example`: referencia del backend (copiala a `backend/.env.local`).
- `frontend/.env.example`: referencia del frontend (copiala a `frontend/.env.local`).

Pasos recomendados:

1. Copi√° `backend/.env.example` a `backend/.env.local` y complet√° los valores necesarios solo en tu m√°quina.
2. Copi√° `frontend/.env.example` a `frontend/.env.local`. Next.js solo expone variables que comienzan con `NEXT_PUBLIC_`.
3. No subas archivos `.env*` con secretos: el `.gitignore` ya los protege y los ejemplos son documentaci√≥n √∫nicamente.

Precedencia en runtime: variables ya presentes en el proceso > `.env.local` > `.env.staging`/`.env.production` > valores por defecto definidos en c√≥digo. Los archivos `*.example` no se cargan autom√°ticamente.

Scripts √∫tiles:

- `make env-sync`: sincroniza `backend/.env.sample` desde el ejemplo principal.
- `make env-validate-backend`: ejecuta `backend/scripts/validate_env.py` dentro del servicio `api`.
- `make env-validate-frontend`: ejecuta `frontend/scripts/validate-env.mjs`.

Antes de levantar los servicios por primera vez:

```bash
cp backend/.env.example backend/.env.local
cp frontend/.env.example frontend/.env.local
```

Luego rellen√° los secretos manualmente y corr√© los validadores (`make env-validate-backend`, `make env-validate-frontend`) para verificar que no falte nada cr√≠tico.

## QA (flujo unificado)

1) Validar entornos
   ```bash
   make env-validate-backend
   make env-validate-frontend
   ```

2) QA completo (genera `qa/QA_SUMMARY.md`)
   ```bash
   make qa-full
   ```

Artefactos:
- `qa/backend-coverage.xml` (PyTest)
- `qa/frontend-coverage/` (Jest)
- `frontend/playwright-report/` (Playwright)

## Web Push

- Configur√° `NEXT_PUBLIC_VAPID_PUBLIC_KEY` en `frontend/.env.local` y `VAPID_PRIVATE_KEY`,
  `VAPID_PUBLIC_KEY`, `VAPID_SUBJECT` en `backend/.env.local`. Sin claves reales el flujo queda en modo seguro.
- El `NotificationCenter` muestra un panel de depuraci√≥n (solo en desarrollo) con acciones para pedir
  permisos, suscribirse/desuscribirse y disparar pruebas. Los logs visibles ayudan a diagnosticar navegadores.
- `make push-info` imprime si el backend carga las claves y qu√© valor tiene el frontend.
- `make push-test` ejecuta `backend/scripts/send_test_push.py` dentro del contenedor y env√≠a una notificaci√≥n
  b√°sica a todas las suscripciones almacenadas.
- Compatibilidad:
  - **Chrome / Edge**: soporte completo; requiere gesto de usuario para solicitar permisos.
  - **Firefox**: soportado; la UI de permisos puede mostrarse fuera de foco, aseg√∫rate de que la pesta√±a est√© activa.
  - **Safari (macOS/iOS)**: requiere HTTPS o `http://localhost` y un gesto expl√≠cito; la notificaci√≥n puede tardar
    unos segundos en mostrarse.
- Regla general: todas las suscripciones usan `userVisibleOnly: true` y el Service Worker muestra la notificaci√≥n al
  recibir un `push` antes de resolver la promesa del evento.

### Web Push ‚Äì Hardening

- Retries con backoff exponencial (410/404 ‚Üí marcadas para pruning, 429 ‚Üí reintentos con backoff progresivo, 5xx ‚Üí reintentos cortos) y logging con `endpoint_fingerprint` para preservar privacidad.
- El servicio incrementa `fail_count`/`last_fail_at` y marca `pruning_marked` ante fallos cr√≠ticos; ejecut√° `make push-prune` (usa `backend/scripts/prune_stale_push_subs.py`) para limpiar suscripciones caducas.
- Los healthchecks incluyen el subcomponente `push` (`/api/health` ‚Üí `services.push`) para verificar la presencia de claves VAPID sin exponerlas.
- Audit trail ligero via `AuditService`: altas/bajas y env√≠os de prueba quedan registrados en los logs de backend.
- La UI respeta la flag `NEXT_PUBLIC_FEATURE_NOTIFICATIONS_DEBUG` (solo activa en desarrollo) y deshabilita la suscripci√≥n cuando detecta claves placeholder.

## Secretos y .env

- `backend/.env` es la fuente de verdad local para credenciales y URIs sensibles (no se versiona). Copi√° solo lo necesario a `backend/.env.local` y `frontend/.env.local` para ejecutar la app.
- `docker-compose.yml` utiliza `backend/.env.local` mediante `env_file`; nunca montes `.env.example` en contenedores.
- Los archivos `.env.example`/`.env.sample` incluyen √∫nicamente placeholders (# QA) y se sincronizan con `tools/sync_env_examples.py`.
- Comandos √∫tiles:
  - `make env-validate-backend`
  - `make env-validate-frontend`
  - `make secrets-scan`
- Regla estricta: ning√∫n secreto real en c√≥digo, docs ni archivos de ejemplo. Usa la checklist `qa/SECRETS_CHECKLIST.md` y el barrido `make secrets-scan` antes de publicar.
- # QA: En redes sin IPv6, define `SUPABASE_DB_HOSTADDR` en `backend/.env.local` para forzar IPv4 (el valor se inserta como `hostaddr=<ip>` en `SUPABASE_DB_URL`).
- # QA: Para forzar conexi√≥n directa sin PgBouncer usando un puente IPv4‚ÜíIPv6, ejecut√° `qa/direct_db_bridge.sh` (requiere `SUPABASE_DIRECT_USER` y `SUPABASE_DIRECT_PASS_URLENC` exportados si `backend/.env.local` no contiene las credenciales). El script levanta el puente con `socat`, reinicia el stack Docker y corre `make db-smoke`/`make db-migrate-direct`.
- Secuencia recomendada para verificar la conexi√≥n directa (IPv4):
  ```bash
  docker compose down
  docker compose up -d --build
  make db-force-ipv4
  make db-smoke
  make db-migrate-direct
  curl -s http://127.0.0.1:8000/api/health | jq .
  ```
- Si `make db-force-ipv4` devuelve `no_ipv4`, define manualmente `SUPABASE_DB_HOSTADDR=<IPv4>` en `backend/.env.local` y vuelve a ejecutar el comando.
- Evitar pegar comentarios (`# ‚Ä¶`) en el shell: zsh los interpreta como comandos si se parte la l√≠nea.

## Puesta en marcha con Docker Compose

1. Genera tu archivo `.env` como se describe arriba.
2. Construye y levanta los contenedores en segundo plano:

   ```bash
   make up           # equivalente a docker compose up -d
   ```

   Servicios incluidos:

   - **db**: PostgreSQL 15 con persistencia en `postgres_data`.
   - **redis**: Redis 7 para rate limiting y caching.
   - **backend**: API FastAPI sirviendo en [http://localhost:8000](http://localhost:8000).
   - **frontend**: Next.js Dev Server disponible en [http://localhost:3000](http://localhost:3000).

3. Sigue los logs combinados cuando lo necesites:

   ```bash
   make logs
   ```

4. Det√©n y limpia los recursos cuando termines:

   ```bash
   make down         # detiene contenedores
   make clean        # detiene y borra vol√∫menes/orphans
   ```

## Configuraci√≥n manual (sin Docker)

1. **Backend**
   ```bash
   python -m venv .venv
   source .venv/bin/activate
   python -m pip install -r backend/requirements.txt
   export $(grep -v '^#' .env | xargs)
   uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
   ```

   Configur√° las variables manualmente si prefer√≠s otro enfoque.

2. **Frontend**
   ```bash
   cd frontend
   npm install
   npm run dev -- --hostname 0.0.0.0 --port 3000
   ```

Aseg√∫rate de tener PostgreSQL y Redis ejecut√°ndose en tu entorno local y que las
variables de entorno apunten a esas instancias.

### Perfil staging con Docker Compose

El `docker-compose.yml` define dos perfiles:

- `default`: entorno de desarrollo con recarga en caliente (`make up`).
- `staging`: entorno de pruebas realistas con builds optimizados.

Para levantar el perfil staging:

```bash
make up-staging       # Levanta backend, frontend, db y redis en modo staging
make down-staging     # Detiene √∫nicamente los servicios del perfil staging
```

En staging el frontend ejecuta `npm start` (Next.js compilado) y el backend
utiliza Uvicorn sin `--reload`, reutilizando los contenedores de PostgreSQL y
Redis con vol√∫menes persistentes.

## Entornos de ejecuci√≥n

| Variable `ENV` | Comportamiento | C√≥mo levantar |
| -------------- | -------------- | ------------- |
| `local`        | El backend crea las tablas autom√°ticamente (`Base.metadata.create_all`) y siembra el usuario por defecto. Ideal para desarrollo r√°pido. | `make up-local` (equivalente a `docker compose --env-file .env.local up -d --build`). |
| `staging` / `prod` | La base de datos **no** se crea autom√°ticamente: se espera que las migraciones de Alembic est√©n aplicadas. | `make up-staging` (staging) o configura tus variables y ejecuta `docker compose --profile staging up -d`. |

Cuando trabajes fuera de `local` debes aplicar las migraciones manualmente:

```bash
make migrate          # docker compose exec backend alembic upgrade head
```

üí° Recomendaci√≥n: tras cada despliegue en staging/prod ejecuta `make migrate` (o el comando equivalente en tu pipeline) antes de exponer la API. Esto garantiza que el esquema coincida con la √∫ltima versi√≥n del c√≥digo.

## Testing

Desde la ra√≠z del repositorio pod√©s lanzar las suites de manera unificada con
los scripts de `pnpm`:

```bash
pnpm test:frontend       # Jest modo desarrollo con watch inteligente
pnpm test:frontend:list  # Lista los tests detectados por Jest
pnpm test:backend        # Pytest completo para el backend
pnpm test:backend:cov    # Pytest con cobertura para backend
```

Si prefer√≠s orquestar todo en un solo paso, mantenemos el objetivo cl√°sico:

```bash
make test
```

- Backend: `python -m pytest backend/tests`
- Frontend: `npm --prefix frontend run test:dev`

- Cobertura en CI: `npm --prefix frontend run test:ci`

> ‚ÑπÔ∏è **Cobertura en Jest**: los tests del frontend mantienen umbrales globales.
> Usa `npm --prefix frontend run test:ci` para validar cobertura estricta en CI.
> Durante el desarrollo utiliza `npm --prefix frontend run test:dev` para
> ejecutar suites filtradas sin fallos por cobertura.

### Smoke manual de la API

Cuando necesites validar r√°pidamente el flujo b√°sico de autenticaci√≥n y alertas
sin montar un entorno completo de pruebas, pod√©s ejecutar esta secuencia de
`curl` desde una shell (`bash`/`zsh`). Asume el backend corriendo en
`http://127.0.0.1:8000`.

```bash
# Registrar un usuario
curl -s -X POST http://127.0.0.1:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{"email":"demo@test.com","password":"demo1234"}' | jq

# Login y captura del token JWT
TOKEN=$(curl -s -X POST http://127.0.0.1:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"demo@test.com","password":"demo1234"}' | jq -r .access_token)
echo "TOKEN=${TOKEN:0:20}..."

# Crear una alerta en el formato nuevo
curl -s -X POST http://127.0.0.1:8000/api/alerts \
  -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"asset":"AAPL","channel":"push","conditions":[{"field":"price","op":">","value":150}]}' | jq

# Listar las alertas del usuario
curl -s -H "Authorization: Bearer $TOKEN" http://127.0.0.1:8000/api/alerts | jq

# Simular una suscripci√≥n push (endpoint ficticio)
curl -s -X POST http://127.0.0.1:8000/api/push/subscribe \
  -H "Authorization: Bearer $TOKEN" -H "Content-Type: application/json" \
  -d '{"endpoint":"https://example.com/push/cli","keys":{"auth":"auth-key","p256dh":"p256dh-key"}}' | jq
```

## Logging estructurado

El backend utiliza utilidades basadas en `structlog` definidas en
[`backend/core/logging_config.py`](backend/core/logging_config.py). La funci√≥n
`log_event` encapsula la escritura de eventos estructurados y a√±ade
metadatos consistentes:

- `service`: servicio o m√≥dulo que emite el log (por ejemplo, `alerts`).
- `event`: descripci√≥n corta y accionable del evento.
- `timestamp`: ISO 8601 en UTC generado autom√°ticamente.
- `error`: campo opcional para adjuntar mensajes de excepci√≥n o trazas.

Pod√©s enlazar contexto adicional mediante kwargs (`user_id`, `payload`, etc.).
El logger serializa el evento como JSON, lo que facilita enviarlo a sistemas de
observabilidad sin parseos adicionales.

## Observabilidad (logs y m√©tricas)

- **Logging estructurado**: el backend utiliza `structlog` con salida JSON. Ajusta
  el nivel con `BULLBEAR_LOG_LEVEL` (`INFO`, `DEBUG`, etc.).
- **M√©tricas Prometheus**: la API expone `/metrics` con histogramas de latencia y
  contadores por endpoint listos para ser scrapeados por Prometheus/Grafana.

## Chat persistente y notificaciones push

- Las conversaciones del asistente se guardan por usuario y sesi√≥n. El endpoint
  `POST /ai/chat` crea sesiones autom√°ticamente y `GET /ai/history/{session_id}`
  devuelve el historial para hidratar el chat en el frontend.
- El frontend conserva el `session_id` en `localStorage` y revalida el historial
  con SWR al montar el componente de chat, garantizando continuidad tras
  recargas o nuevos inicios de sesi√≥n.
- El Service Worker (`frontend/public/sw.js`) gestiona la recepci√≥n de
  notificaciones push. El hook `usePushNotifications` registra la suscripci√≥n
  usando la clave VAPID p√∫blica y expone el estado al dashboard.
- Para emitir pruebas de push, usa `POST /push/subscribe` en el backend y la
  utilidad `backend/services/push_service.py` para despachar mensajes mediante
  `pywebpush`. Cuando `pywebpush` no est√° instalado, el servicio degrada de
  forma segura registrando el intento en logs.

## Roadmap MVP

- [x] **Crypto** ‚Äì precios en vivo desde proveedores externos.
- [x] **Forex** ‚Äì cotizaciones de pares principales con cach√©.
- [x] **AI chat b√°sico** ‚Äì asistente conversacional con contexto de mercado.
- [x] **News** ‚Äì agregador de noticias financieras y cripto.
- [x] **Alertas** ‚Äì creaci√≥n, listado, actualizaci√≥n y env√≠o de alertas personalizadas.
- [ ] **Automatizaci√≥n avanzada** ‚Äì integraci√≥n con brokers y ejecuci√≥n de √≥rdenes.

## Recursos adicionales

- [Documentaci√≥n FastAPI](https://fastapi.tiangolo.com/)
- [Documentaci√≥n Next.js](https://nextjs.org/docs)
- [SQLAlchemy 2.x](https://docs.sqlalchemy.org/)

¬°Sugerencias y contribuciones son bienvenidas! Abre un issue o PR para seguir
iterando sobre el asistente financiero inteligente de BullBearBroker.

## üîß Desarrollo r√°pido

```bash
python -m pip install -r backend/requirements.txt
python -m pip install -r backend/requirements-dev.txt
pre-commit install
make lint
make test
Generar OpenAPI/Postman:
make openapi      # postman/openapi.json
make postman      # postman/BullBearBroker.postman_collection.json
```

üß™ CI
Este repo incluye GitHub Actions (.github/workflows/ci.yml) con lint (ruff/black/isort) y tests (pytest) en Python 3.12.

‚úÖ Aceptaci√≥n (debe pasar)
python -m pip install -r backend/requirements.txt
python -m pip install -r backend/requirements-dev.txt
pre-commit run --all-files (o make lint)
pytest backend -q (debe quedar en verde)
make postman crea postman/BullBearBroker.postman_collection.json

## Running backend tests isolated on Supabase Session Pooler

Some CI/dev envs are IPv4-only. Use Supabase Session Pooler (IPv4) and isolate the test run in a dedicated schema to avoid residual data and PgBouncer prepared-statement issues.

### One-time
```bash
chmod +x qa/test_isolated.sh
```

```bash
# Replace with your Session Pooler DSN from Supabase (user/pass redacted here):
export SUPABASE_POOLER_URL='postgresql+psycopg://postgres.<project>:<password>@aws-1-us-east-2.pooler.supabase.com:5432/postgres'

# Run isolated suite (creates a test_YYYYmmdd_HHMMSS schema, migrates it to head and runs tests)
qa/test_isolated.sh

# Optional: custom schema name, extra pytest opts, and cleanup at the end:
qa/test_isolated.sh --schema my_ephemeral_schema --pytest-opts "-k rate_limits -q" --drop-after
```

The runner:
- forces TLS (`sslmode=require`) and disables prepared statements for PgBouncer via SQLAlchemy connect args;
- sets the `search_path` to the ephemeral schema;
- runs Alembic migrations on that schema;
- executes the suite without polluting other schemas.

Notes
- Keep secrets out of commits and terminals; the script masks user/password in its preview logs.
- If your Pooler hostname differs (e.g. `aws-0-‚Ä¶`), just set `SUPABASE_POOLER_URL` accordingly.
