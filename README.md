## BullBearBroker

### Requisitos previos

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/) (Docker Desktop ya lo incluye)
- Opcional: `make` si prefieres ejecutar comandos abreviados

### Variables de entorno

Crea un archivo `.env` en la ra√≠z del proyecto con las variables necesarias para la API. Puedes usar el siguiente ejemplo como punto de partida:

```env
# Seguridad JWT
BULLBEARBROKER_SECRET_KEY="coloca_aqu√≠_una_clave_aleatoria_segura"
# BULLBEARBROKER_JWT_ALGORITHM="HS256"  # opcional

# Credenciales para la base de datos (opcional si usas docker-compose por defecto)
# POSTGRES_USER=bullbear
# POSTGRES_PASSWORD=bullbear
# POSTGRES_DB=bullbear

# Claves para servicios externos (todas opcionales)
# ALPHA_VANTAGE_API_KEY=
# TWELVEDATA_API_KEY=
# COINGECKO_API_KEY=
# COINMARKETCAP_API_KEY=
# NEWSAPI_API_KEY=
# CRYPTOPANIC_API_KEY=
# MEDIASTACK_API_KEY=
```

> üí° Genera una clave segura ejecutando `python -c "import secrets; print(secrets.token_urlsafe(64))"`.

Si la variable `BULLBEARBROKER_SECRET_KEY` no est√° definida, el backend crear√° una clave aleatoria en cada arranque, lo que invalida cualquier token emitido previamente.

### Ejecuci√≥n con Docker Compose

1. Construye e inicia los servicios (backend, PostgreSQL y Redis):

   ```bash
   docker compose up --build
   ```

   El backend quedar√° disponible en [http://localhost:8000](http://localhost:8000).

2. Cuando termines, det√©n los servicios con:

   ```bash
   docker compose down
   ```

   Para limpiar completamente los vol√∫menes de datos (por ejemplo, reiniciar la base de datos), ejecuta `docker compose down -v`.

#### Atajos con `make`

Si cuentas con `make`, el proyecto incluye un `Makefile` con los siguientes atajos:

- `make build` ‚Äì equivalente a `docker compose up --build`
- `make up` ‚Äì levanta los servicios ya construidos
- `make down` ‚Äì detiene los contenedores
- `make clean` ‚Äì elimina contenedores, redes y vol√∫menes asociados
- `make logs` ‚Äì muestra los logs combinados de los servicios

### Migraciones de base de datos

El backend utiliza [Alembic](https://alembic.sqlalchemy.org/) para gestionar los cambios de esquema. Cada vez que actualices el c√≥digo aseg√∫rate de aplicar las migraciones m√°s recientes con:

```bash
docker compose run --rm backend alembic upgrade head
```

> Si ejecutas el backend fuera de Docker, aseg√∫rate de tener la variable `DATABASE_URL` apuntando a tu instancia de PostgreSQL antes de lanzar `alembic upgrade head`.

### Desarrollo sin Docker

Los scripts de `npm` siguen disponibles para desarrollo local sin contenedores:

1. Instala las dependencias del frontend con `npm install`.
2. Levanta el frontend est√°tico con `npm run start` y accede a [http://localhost:8080](http://localhost:8080).
3. Inicia el backend con `npm run backend` (lanza Uvicorn en [http://localhost:8000](http://localhost:8000)).

Det√©n cada proceso con `Ctrl+C` cuando termines.

### A√±adir nuevas fuentes de datos

Las integraciones de precios y noticias est√°n desacopladas mediante servicios especializados.
Para conectar una nueva fuente:

1. **Crea o actualiza un servicio** con un m√©todo `get_price` (o equivalente) que devuelva los
   datos normalizados. Puedes inspirarte en `backend/services/crypto_service.py` y
   `backend/services/stock_service.py`.
2. **Inyecta la dependencia** en `MarketService` pasando el servicio en el constructor o
   registr√°ndolo dentro de la clase si debe ser la fuente por defecto.
3. **Gestiona la cach√©** reutilizando `utils.cache.CacheClient` para evitar llamadas repetidas.
4. **Actualiza los helpers del mercado** (`get_crypto_price`, `get_stock_price`, `get_news`) para que
   deleguen en la nueva fuente y a√±ade la clave necesaria en `.env`.

De forma similar, las nuevas APIs de noticias pueden integrarse creando un m√©todo auxiliar que
devuelva la estructura `{title, url, source, published_at, summary}` y registr√°ndolo como fallback
antes de la lectura RSS.
